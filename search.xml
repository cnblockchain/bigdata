<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[flume详解]]></title>
    <url>%2F2017%2F08%2F11%2Fflume%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[sqoop2使用实例]]></title>
    <url>%2F2017%2F08%2F11%2Fsqoop2%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[Sqoop是一款开源的工具，主要用于在Hadoop和传统的数据库(MySQL、postgresql等)进行数据的传递，可以将一个关系型数据库（例如：mysql、Oracle、Postgres等）中的数据导进到hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。Sqoop中一大亮点就是可以通过hadoop的mapreduce把数据从关系型数据库中导入数据到HDFS。Sqoop目前版本已经到了1.99.7，我们可以在其官网上看到所有的版本，Sqoop1.99.7是属于sqoop2，Sqoop1的最高版本为1.4.6sqoop2的官方文档：http://sqoop.apache.org/docs/1.99.7/index.html sqoop2的使用过程使用 show connector 查看sqoop的所有连接123456789sqoop:000&gt; show connector+----+------------------------+----------------+------------------------------------------------------+----------------------+| Id | Name | Version | Class | Supported Directions |+----+------------------------+----------------+------------------------------------------------------+----------------------+| 1 | kite-connector | 1.99.6-bc1.3.2 | org.apache.sqoop.connector.kite.KiteConnector | FROM/TO || 2 | kafka-connector | 1.99.6-bc1.3.2 | org.apache.sqoop.connector.kafka.KafkaConnector | TO || 3 | hdfs-connector | 1.99.6-bc1.3.2 | org.apache.sqoop.connector.hdfs.HdfsConnector | FROM/TO || 4 | generic-jdbc-connector | 1.99.6-bc1.3.2 | org.apache.sqoop.connector.jdbc.GenericJdbcConnector | FROM/TO |+----+------------------------+----------------+------------------------------------------------------+----------------------+ 在向hdfs导入导出数据时，需要依赖以上四个连接创建link （在1.99.4版本之后 用户不需要再创建连接） 查看当前的所有link12345sqoop:000&gt; show link +----+------+--------------+----------------+---------+| Id | Name | Connector Id | Connector Name | Enabled |+----+------+--------------+----------------+---------++----+------+--------------+----------------+---------+ 查看当前的所有job12345sqoop:000&gt; show job+----+------+----------------+--------------+---------+| Id | Name | From Connector | To Connector | Enabled |+----+------+----------------+--------------+---------++----+------+----------------+--------------+---------+ 创建link创建hdfs连接（根据connector选择一个合适的连接方式） 12345678sqoop:000&gt; create link -cid 3Creating link for connector with id 3Please fill following values to create new link objectName: hdfs_linkLink configurationHDFS URI: hdfs://kiwi01.novalocal:8020Hadoop conf directory: /cmss/bch/bc1.3.4/hadoop/etc/hadoopNew link was successfully created with validation status OK and persistent id 2 查看创建的连接 123456sqoop:000&gt; show link+----+-----------+--------------+----------------+---------+| Id | Name | Connector Id | Connector Name | Enabled |+----+-----------+--------------+----------------+---------+| 2 | hdfs_link | 3 | hdfs-connector | true |+----+-----------+--------------+----------------+---------+ 创建mysql的link 123456789101112131415161718sqoop:000&gt; create link -cid 4Creating link for connector with id 4Please fill following values to create new link objectName: mysql_linkLink configurationJDBC Driver Class: com.mysql.jdbc.DriverJDBC Connection String: jdbc:mysql://hcontrol1341/kiwiUsername: kiwiPassword: ****JDBC Connection Properties: There are currently 0 values in the map:entry# protocol=tcpThere are currently 1 values in the map:protocol = tcpentry# New link was successfully created with validation status OK and persistent id 5 查看创建的link 1234567sqoop:000&gt; show link+----+------------+--------------+------------------------+---------+| Id | Name | Connector Id | Connector Name | Enabled |+----+------------+--------------+------------------------+---------+| 2 | hdfs_link | 3 | hdfs-connector | true || 5 | mysql_link | 4 | generic-jdbc-connector | true |+----+------------+--------------+------------------------+---------+ 创建job123456789101112131415161718192021222324252627282930313233343536373839404142434445464748sqoop:000&gt; create job -f 5 -t 2Creating job for links with from id 5 and to id 2Please fill following values to create new job objectName: mysql_to_hdfsFrom database configurationSchema name: employeesTable name: dept_managerTable SQL statement: Table column names: Partition column name: Null value allowed for the partition column: Boundary query: Incremental readCheck column: Last value: To HDFS configurationOverride null value: Null value: Output format: 0 : TEXT_FILE 1 : SEQUENCE_FILEChoose: 0Compression format: 0 : NONE 1 : DEFAULT 2 : DEFLATE 3 : GZIP 4 : BZIP2 5 : LZO 6 : LZ4 7 : SNAPPY 8 : CUSTOMChoose: 0Custom compression format: Output directory: hdfs://kiwi01.novalocal:8020/sqoopAppend mode: Throttling resourcesExtractors: 2Loaders: 2New job was successfully created with validation status OK and persistent id 1 查看job的状态 123456sqoop:000&gt; show job+----+---------------+----------------+--------------+---------+| Id | Name | From Connector | To Connector | Enabled |+----+---------------+----------------+--------------+---------+| 1 | mysql_to_hdfs | 4 | 3 | true |+----+---------------+----------------+--------------+---------+ 启动job12345678910sqoop:000&gt; start job -j 1Submission detailsJob ID: 1Server URL: http://localhost:12000/sqoop/Created by: sqoop2Creation date: 2017-08-03 18:55:46 CSTLastly updated by: sqoop2External ID: job_1501745270549_0001 http://kiwi01.novalocal:8088/proxy/application_1501745270549_0001/2017-08-03 18:55:46 CST: BOOTING - Progress is not available 查看job的状态12345678910sqoop:000&gt; status job -j 1Submission detailsJob ID: 1Server URL: http://localhost:12000/sqoop/Created by: sqoop2Creation date: 2017-08-03 18:55:46 CSTLastly updated by: sqoop2External ID: job_1501745270549_0001 http://kiwi01.novalocal:8088/proxy/application_1501745270549_0001/2017-08-03 18:56:06 CST: RUNNING - 0.00 % End]]></content>
      <categories>
        <category>Sqoop2</category>
      </categories>
      <tags>
        <tag>sqoop</tag>
        <tag>sqoop2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F08%2F10%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>HDFS</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
</search>
